# NISO

## Lecture2
* Brute-force 蛮力解决方案时间复杂度位 O(n<sup>2</sup>)  

#### 因此有了启发式算法
* 比如Local Search e.g. greedy search
* Randomised algorithms, which include Evolutionary Computation

#### 启发式算法的定义
A (usually simple) algorithm that produces a **good enough** solution for a problem in a reasonable time frame.

## 两个随机算法
给一个包含n个数的数组，找到一个数的值等于x
### Las Vegas
``` 
begin
	repeat
			Randomly select one element a out of n elements
	until a == x
end

``` 
### Monte Carlo
多了一个判定条件，循环次数到一定之后也会停止
``` 
begin
	i = 0
	while (i == k || a == x)
		Randomly select one element a out of n elements
		i += 1
	end
end
``` 

### 这两个的区别
* Monte Carlo的运行步数是固定的
* Las Vegas相当于是在无限循环，直到找到正确结果

## Lecture3
* 用启发式算法解决TSP问题
	* 随机算法 Randomised Algorithms
	* 局部搜索 Local Search Algorithms

### TSP问题对于其它算法是很难的
* 主要是在时间复杂度上
	* Brute force 需要O(n!), 需要花费大量的时间
* 需要注意的是 随机算法仍旧有效，因为它的exploration性质，但由于纯随机算法无法exploitation，不能利用有效的结果，因此纯随机算法是不好的。但结合起来是可以的

### Local Search Algorithm 局部搜索算法
* 用于解决难移优化问题的启发式算法
	* 从对解决方案的初步猜测开始，逐步改进它，直到得到最优解  
	Start with an initial guess at a solution and incrementally improve it until it is one.
	* 增量改进: 局部变化，例如慢慢迭代移动到邻近解  
	Incremental improvement: local changes, e.g. the algorithm iteratively moves to a neighbour solution.

``` 
X0 = 初始解
new_best = X0
while()
	Modify current solution to neighbourhood solution
	如果当前解是更好解 则赋值当前解到new_best
	直至满足终止条件退出

``` 

#### 局部搜索中的爬山算法
* 最简单的局部搜索之一
* 引入的一个重要概念是immediate neighbour solutions: most similar solutions to the current solution.

* 两种实现方法
	* Simple hill climbing: chooses the **first** better solution
	* Steepest ascent hill climbing: compares all neighbour solutions and chooses the best solution.

* 伪代码和就是上面的局部搜索算法，增量改进中把邻近解改为直接邻近解

### 爬山算法在TSP中的应用
* 2-opt （重要）
	* 选两个点，切断路线 交换顺序重新连接即可
* 但2-opt是一个局部搜索方法，因此我们需要接入随机性来提升效果

<br/>

### Simulated Annealing
以一定概率去接受差解，来逃离局部最优

不用默写伪代码，但你需要了解它的机制
伪代码
``` 
``` 
### Representation (子代的形式)
* representation的选择基于不同的问题
	* Binary Representation 二进制表现 (L5-15页)
	* Real number representation 实数表现，解决工程优化问题


### Selection Schemes 选择机制
* 深度了解其中一种选择机制 并在说明你在GA中为什么要用这个选择机制(他们之间的区别其实不大)

### Real-valued coded evolutionary algorithms
* Real valued mutation 有两种形式，你需要了解其中一种并作出解释
* Uniform mutation / Gaussian mutation: replace ci with random
* Non-uniform mutation


## 最后一个重要的部分：Constraint Handling
* 限制优化问题是什么
* 如何处理这些限制的？

### 惩罚机制
* 在原有的fitness函数中增加惩罚机制

* 几种不同的惩罚方法
	* static penalties
	* dynamic penalties
	* adaptive and self-adaptive penalties

* 一句话解释这个  
* 改变ranking的排序，不仅仅基于fitness，还有violation of constraint