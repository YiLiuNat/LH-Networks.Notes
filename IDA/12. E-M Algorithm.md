# E-M Algorithm
***(GMMs.pdf 第31页，Panopto: 14 March 2019 at 10:52 (23:45))***

* 我现在有一个数据x<sub>n</sub>, 但我并不知道这个数据是属于哪一个component的  
![](./img/EM.JPG)  
* 先猜测M的个数为2，那么我们不单猜测M为2，我们把别的也都给猜了
* 这和K-means很像，我们也是先猜centroids在哪个位置 然后再让算法去跑
<br/>

* 我们再把P<sub>1</sub>和P<sub>2</sub>的m和v给猜测了  
![](./img/EM2.JPG) 
* 根据我们猜测的m1 m2位置，把图像画出  
![](./img/EM3.JPG) 

* 现在我们能看出x<sub>n</sub>在p<sub>1</sub>和p<sub>2</sub>上的值分别是多少
![](./img/EM4.JPG)

* 然后用贝叶斯定理算 P(c<sub>1</sub>|x<sub>n</sub>) //c<sub>1</sub>指component1 算的是the probability of component 1 given by data point Xn 
![](./img/EM5.JPG)
* 刚好下面一坨就是p(x<sub>n</sub>)
* 然后同样的算法算P(c<sub>2</sub>|x<sub>n</sub>) 看哪个更大  
![](./img/EM6.JPG)
* 对于每一个数据点，都这样算，就能分出该数据点属于哪一边

## 总结E-M算法
1. 猜测(Guess) P1(m1,v1), P2(m2,v2)，然后再猜权重w1,w2  
![](./img/EM7.JPG)
2. 对于每个数据点Xn, 每个component c1 & c2, 计算 P(c<sub>1</sub>|x<sub>n</sub>)和P(c<sub>2</sub>|x<sub>n</sub>)  
![](./img/EM8.JPG)
3. 定义新的m1的位置  
![](./img/EM9.JPG)